{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bnn.data\n",
    "import bnn.functions\n",
    "import bnn.layer\n",
    "import bnn.loss\n",
    "import bnn.network\n",
    "import bnn.optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_func = bnn.functions.forward.SignBinarise()\n",
    "#forward_func=bnn.functions.forward.LayerMeanBinarise()\n",
    "#forward_func=bnn.functions.forward.LayerMedianBinarise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "backward_func = bnn.functions.backward.SignTernarise()\n",
    "#backward_func = bnn.functions.backward.StochasticTernarise()\n",
    "#backward_func = bnn.functions.backward.LayerMeanStdTernarise(half_range_stds=0.5)\n",
    "#backward_func = bnn.functions.backward.LayerQuantileTernarise(lo=0.25, hi=0.75)\n",
    "#backward_func = bnn.functions.backward.LayerQuantileSymmetricTernarise(prop_zero=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 128\n",
    "OUTPUT_DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_DIM = INPUT_DIM\n",
    "NUM_LAYERS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [INPUT_DIM] + [HIDDEN_DIM] * (NUM_LAYERS - 1) + [OUTPUT_DIM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_TBNN = bnn.network.TernBinNetwork(\n",
    "    dims,\n",
    "    forward_func=forward_func,\n",
    "    backward_func=backward_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "noproj_TBNN = bnn.network.TernBinNetwork(\n",
    "    dims,\n",
    "    forward_func=forward_func,\n",
    "    backward_func=bnn.functions.backward.ActualGradient(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_weights(source: bnn.network.TernBinNetwork, target: bnn.network.TernBinNetwork):\n",
    "    for name, layer in source.layers.items():\n",
    "        target.layers[name].W.data = layer.W.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_same_weights(source: bnn.network.TernBinNetwork, target: bnn.network.TernBinNetwork):\n",
    "    for name, layer in source.layers.items():\n",
    "        assert torch.equal(target.layers[name].W.data, layer.W.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_sign_confmats(\n",
    "    input: torch.Tensor, \n",
    "    grad: torch.Tensor, \n",
    "    net1: bnn.network.TernBinNetwork, \n",
    "    net2: bnn.network.TernBinNetwork,\n",
    ") -> dict[str, torch.Tensor]:\n",
    "    # forward\n",
    "    net1.forward(input)\n",
    "    net2.forward(input)\n",
    "\n",
    "    # backward\n",
    "    net1.backward(grad)\n",
    "    net2.backward(grad)\n",
    "\n",
    "    confmats = {}\n",
    "    for name in net1.layers:\n",
    "        confmat = _grad_sign_confmat(net1.grad[name], net2.grad[name])\n",
    "        confmats[name] = confmat\n",
    "    \n",
    "    return confmats\n",
    "\n",
    "\n",
    "def _grad_sign_confmat(out1, out2):\n",
    "    sign_out1 = torch.sign(out1)\n",
    "    sign_out2 = torch.sign(out2)\n",
    "\n",
    "    out = torch.empty(size=[3, 3])\n",
    "\n",
    "    SYMBOLS = (-1, 0, 1)\n",
    "    for i in SYMBOLS:\n",
    "        for j in SYMBOLS:\n",
    "            out[i, j] = torch.sum(sign_out2[sign_out1 == i] == j)\n",
    "\n",
    "    out /= out.sum()\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confmat(confmat: torch.Tensor):\n",
    "    print(\n",
    "        \"\\t Actual grad sign\\n\"\n",
    "        \"\\t 0 \\t 1 \\t -1 \\t sum\\n\"\n",
    "        \"----------------------------------\\n\"\n",
    "        f\" 0  |\\t {confmat[0, 0]:.3f} \\t {confmat[1, 0]:.3f} \\t {confmat[-1, 0]:.3f} \\t| {confmat[:, 0].sum():.3f}\\n\"\n",
    "        f\" 1  |\\t {confmat[0, 1]:.3f} \\t {confmat[1, 1]:.3f} \\t {confmat[-1, 1]:.3f} \\t| {confmat[:, 1].sum():.3f}\\n\"\n",
    "        f\"-1  |\\t {confmat[0, -1]:.3f} \\t {confmat[1, -1]:.3f} \\t {confmat[-1, -1]:.3f} \\t| {confmat[:, -1].sum():.3f}\\n\"\n",
    "        \"----------------------------------\\n\"\n",
    "        f\"sum |\\t {confmat[0, :].sum():.3f} \\t {confmat[1, :].sum():.3f} \\t {confmat[-1, :].sum():.3f} \\t| {confmat.sum():.3f}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confmat_nonzero_sign_error(confmat) -> float:\n",
    "    nonzero = confmat[1].sum() + confmat[-1].sum()\n",
    "    wrong_sign = confmat[1, -1] + confmat[-1, 1]\n",
    "\n",
    "    prop = wrong_sign / nonzero\n",
    "\n",
    "    return prop.item()\n",
    "\n",
    "def confmat_nonzero_sign_error_inc0(confmat) -> float:\n",
    "    nonzero = confmat[1].sum() + confmat[-1].sum()\n",
    "    wrong_sign = confmat[1, -1] + confmat[-1, 1]\n",
    "    zero = confmat[1, 0] + confmat[-1, 0]\n",
    "\n",
    "    prop = (wrong_sign + zero) / nonzero\n",
    "\n",
    "    return prop.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable_zero_prob = 0.99 * (1 - 1/HIDDEN_DIM)\n",
    "proj_TBNN._initialise(W_mean=0, W_zero_prob=stable_zero_prob)\n",
    "list(proj_TBNN.layers.values())[-1]._initialise_W(mean=0, zero_prob=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_weights(source=proj_TBNN, target=noproj_TBNN)\n",
    "assert_same_weights(source=proj_TBNN, target=noproj_TBNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  TernBinLayer0\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.556 \t 0.062 \t 0.066 \t| 0.683\n",
      " 1  |\t 0.004 \t 0.090 \t 0.053 \t| 0.148\n",
      "-1  |\t 0.000 \t 0.045 \t 0.123 \t| 0.169\n",
      "----------------------------------\n",
      "sum |\t 0.560 \t 0.197 \t 0.243 \t| 1.000\n",
      "\n",
      "layer:  TernBinLayer1\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.572 \t 0.045 \t 0.053 \t| 0.671\n",
      " 1  |\t 0.000 \t 0.111 \t 0.041 \t| 0.152\n",
      "-1  |\t 0.004 \t 0.062 \t 0.111 \t| 0.177\n",
      "----------------------------------\n",
      "sum |\t 0.576 \t 0.218 \t 0.206 \t| 1.000\n",
      "\n",
      "layer:  TernBinLayer2\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.585 \t 0.058 \t 0.066 \t| 0.708\n",
      " 1  |\t 0.004 \t 0.099 \t 0.053 \t| 0.156\n",
      "-1  |\t 0.004 \t 0.037 \t 0.095 \t| 0.136\n",
      "----------------------------------\n",
      "sum |\t 0.593 \t 0.193 \t 0.214 \t| 1.000\n",
      "\n",
      "layer:  TernBinLayer3\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.560 \t 0.066 \t 0.045 \t| 0.671\n",
      " 1  |\t 0.004 \t 0.132 \t 0.021 \t| 0.156\n",
      "-1  |\t 0.012 \t 0.041 \t 0.119 \t| 0.173\n",
      "----------------------------------\n",
      "sum |\t 0.576 \t 0.239 \t 0.185 \t| 1.000\n",
      "\n",
      "layer:  TernBinLayer4\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.572 \t 0.045 \t 0.058 \t| 0.675\n",
      " 1  |\t 0.025 \t 0.111 \t 0.012 \t| 0.148\n",
      "-1  |\t 0.012 \t 0.021 \t 0.144 \t| 0.177\n",
      "----------------------------------\n",
      "sum |\t 0.609 \t 0.177 \t 0.214 \t| 1.000\n",
      "\n",
      "layer:  TernBinLayer5\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.581 \t 0.029 \t 0.045 \t| 0.655\n",
      " 1  |\t 0.004 \t 0.148 \t 0.016 \t| 0.169\n",
      "-1  |\t 0.016 \t 0.021 \t 0.140 \t| 0.177\n",
      "----------------------------------\n",
      "sum |\t 0.601 \t 0.197 \t 0.201 \t| 1.000\n",
      "\n",
      "layer:  TernBinLayer6\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.609 \t 0.058 \t 0.021 \t| 0.687\n",
      " 1  |\t 0.008 \t 0.132 \t 0.008 \t| 0.148\n",
      "-1  |\t 0.012 \t 0.004 \t 0.148 \t| 0.164\n",
      "----------------------------------\n",
      "sum |\t 0.630 \t 0.193 \t 0.177 \t| 1.000\n",
      "\n",
      "layer:  TernBinLayer7\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.675 \t 0.021 \t 0.012 \t| 0.708\n",
      " 1  |\t 0.000 \t 0.148 \t 0.000 \t| 0.148\n",
      "-1  |\t 0.012 \t 0.000 \t 0.132 \t| 0.144\n",
      "----------------------------------\n",
      "sum |\t 0.687 \t 0.169 \t 0.144 \t| 1.000\n",
      "\n",
      "layer:  TernBinLayer8\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.646 \t 0.000 \t 0.000 \t| 0.646\n",
      " 1  |\t 0.000 \t 0.173 \t 0.000 \t| 0.173\n",
      "-1  |\t 0.000 \t 0.000 \t 0.181 \t| 0.181\n",
      "----------------------------------\n",
      "sum |\t 0.646 \t 0.173 \t 0.181 \t| 1.000\n",
      "\n",
      "layer:  TernBinLayer9\n",
      "\t Actual grad sign\n",
      "\t 0 \t 1 \t -1 \t sum\n",
      "----------------------------------\n",
      " 0  |\t 0.650 \t 0.000 \t 0.000 \t| 0.650\n",
      " 1  |\t 0.000 \t 0.132 \t 0.000 \t| 0.132\n",
      "-1  |\t 0.000 \t 0.000 \t 0.218 \t| 0.218\n",
      "----------------------------------\n",
      "sum |\t 0.650 \t 0.132 \t 0.218 \t| 1.000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NUM_SAMPLES = 1024\n",
    "input = bnn.random.generate_random_binary_tensor(shape=[NUM_SAMPLES, INPUT_DIM], mean=0)\n",
    "grad = bnn.random.generate_random_binary_tensor(shape=[NUM_SAMPLES, OUTPUT_DIM], mean=0)\n",
    "\n",
    "confmats = grad_sign_confmats(input=input, grad=grad, net1=noproj_TBNN, net2=proj_TBNN)\n",
    "\n",
    "for name, confmat in confmats.items():\n",
    "    print(\"layer: \", name)\n",
    "    print_confmat(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer:  TernBinLayer0\n",
      "nonzero wrong sign prop: 0.224\n",
      "nonzero wrong sign (inc0) prop: 0.514\n",
      "layer:  TernBinLayer1\n",
      "nonzero wrong sign prop: 0.243\n",
      "nonzero wrong sign (inc0) prop: 0.476\n",
      "layer:  TernBinLayer2\n",
      "nonzero wrong sign prop: 0.222\n",
      "nonzero wrong sign (inc0) prop: 0.525\n",
      "layer:  TernBinLayer3\n",
      "nonzero wrong sign prop: 0.146\n",
      "nonzero wrong sign (inc0) prop: 0.408\n",
      "layer:  TernBinLayer4\n",
      "nonzero wrong sign prop: 0.084\n",
      "nonzero wrong sign (inc0) prop: 0.347\n",
      "layer:  TernBinLayer5\n",
      "nonzero wrong sign prop: 0.093\n",
      "nonzero wrong sign (inc0) prop: 0.278\n",
      "layer:  TernBinLayer6\n",
      "nonzero wrong sign prop: 0.033\n",
      "nonzero wrong sign (inc0) prop: 0.244\n",
      "layer:  TernBinLayer7\n",
      "nonzero wrong sign prop: 0.000\n",
      "nonzero wrong sign (inc0) prop: 0.105\n",
      "layer:  TernBinLayer8\n",
      "nonzero wrong sign prop: 0.000\n",
      "nonzero wrong sign (inc0) prop: 0.000\n",
      "layer:  TernBinLayer9\n",
      "nonzero wrong sign prop: 0.000\n",
      "nonzero wrong sign (inc0) prop: 0.000\n"
     ]
    }
   ],
   "source": [
    "for name, confmat in confmats.items():\n",
    "    print(\"layer: \", name)\n",
    "    print(f\"nonzero wrong sign prop: {confmat_nonzero_sign_error(confmat):.3f}\")\n",
    "    print(f\"nonzero wrong sign (inc0) prop: {confmat_nonzero_sign_error_inc0(confmat):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
